# MachineLearing
### 决策树(决策树.ipython)
- 比起K近邻算法无法给出数据的内在含义而决策树可以使数据形式非常容易理解
- 优点：计算复杂度不高，输出结果易于理解，对于中间值的缺失不敏感，可以处理不相关特征数据
- 确定：可能产生过渡匹配问题

### K-近邻算法学习(KNN.ipython)
- 原理：对于测试新样本数据的特征和样本集数据对应特征比较取前k个最相似的数据。最后，选K个最相似数据中出现次数最多的分类，作为新数据的分类
- 优点：精度高，对异常值不敏感，无数据输入假定
- 缺点：计算复杂度高，空间复杂度高。适应数据范围：数值型和标称型
